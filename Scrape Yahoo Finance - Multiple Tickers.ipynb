{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Before importing the libraries below, make sure they are installed. You can use Anaconda-Navigator's GUI or it's command line program called conda. You can also use the pip command.\n",
    "Example install commands:\n",
    "\n",
    "conda install pandas\n",
    "pip install pandas\n",
    "\n",
    "conda install beautifulsoup4\n",
    "pip install beautifulsoup4\n",
    "'''\n",
    "\n",
    "# Import library to make HTTP requests, i.e fetch URL similar to a browser request\n",
    "import requests\n",
    "# Import web scraping library\n",
    "from bs4 import BeautifulSoup\n",
    "# Import data analysis and export library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of tickers to loop through and scrape for its historical pricing data.\n",
    "tickers = ['SPY','IWO']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize an empty Python dictionary to store the DataFrames for each ticker.\n",
    "df_dict = {}\n",
    "\n",
    "for ticker in tickers:\n",
    "    \n",
    "    # Request Yahoo Finance URL for a ticker's history (date range defaults to the past year).\n",
    "    # https://finance.yahoo.com/quote/SPY/history\n",
    "\n",
    "    yahoo_finance_url = 'https://finance.yahoo.com/quote/' + ticker + '/history'\n",
    "    page = requests.get(yahoo_finance_url)\n",
    "\n",
    "    # Assign HTML content to a BeautifulSoup object to facilitate web scraping.\n",
    "    # html.parser is one of four parser libraries.\n",
    "    # Description of each parser library: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "    # Find all of the HTML table rows containing the historical data by looking for an HTML tab and its defining attribute.\n",
    "    # You can inspect the HTML elements by using the Chrome browser and right clicking over the desired element and clicking \"Inspect.\"\n",
    "    # Raw HTML of the table row:\n",
    "    # <tr class=\"BdT Bdc($c-fuji-grey-c) Ta(end) Fz(s) Whs(nw)\">\n",
    "    historical_prices = soup.select('tr[class=\"BdT Bdc($c-fuji-grey-c) Ta(end) Fz(s) Whs(nw)\"]')\n",
    "\n",
    "    # Create an empty Python dictionary data structure to keep track of the found price dates and the adjusted closing price for each row.\n",
    "    # The value for each dictionary key is an empty list.\n",
    "    # The number of items in the value list for the price_date and price_adj_close keys must be identical.\n",
    "    # Dictionary initialization must be in the same cell to clear it out each time you're testing the scrape.\n",
    "    # Data is appended and may lead to mismatched column counts.\n",
    "    historical_data = {\n",
    "        'price_date' : [],\n",
    "        'price_adj_close' : []\n",
    "    }\n",
    "\n",
    "    # \"for\" loop through the found rows of historical data. Each row represents a single date.\n",
    "    for historical_price in historical_prices:\n",
    "\n",
    "        # display a horizontal line to easily distinguish between each row\n",
    "        print(\"\\n----------------\\n\")\n",
    "\n",
    "        # Price Adj Close\n",
    "        # Need to find price adj close first b/c not all rows have it due to a row with just the dividend.\n",
    "        # <td class=\"Py(10px) Pstart(10px)\"><span>278.25</span></td>\n",
    "        # Find the HTML table cell tag (td) with the class value of \"Py(10px) Pstart(10px)\"\n",
    "        rows = historical_price.select('td[class=\"Py(10px) Pstart(10px)\"]')\n",
    "\n",
    "        # Proceed if the HTML table cell tag is found with the class value defined above.\n",
    "        if rows:\n",
    "            # The following print statements are for debugging to show how the price adj close was found.\n",
    "            # Price Adj Close is the 5th HTML table cell.\n",
    "            # There are multiple HTML table cells with the class attribute value of \"Py(10px) Pstart(10px)\"\n",
    "            #print(rows)\n",
    "            print(\"price_adj_close HTML:\",rows[4])\n",
    "            # .text will exclude the HTML tags and only get the text\n",
    "            # \"\\n\" is a newline to format the debugging output\n",
    "            print(\"price_adj_close text:\",rows[4].text,\"\\n\")\n",
    "            price_adj_close = rows[4].text\n",
    "\n",
    "            # Append the found price adj close to the price_adj_close dictionary key which we'll reference later when exporting the results.\n",
    "            historical_data['price_adj_close'].append(price_adj_close)\n",
    "\n",
    "\n",
    "            # Price Date\n",
    "            # The price date has its own unique class value for the HTML table cell that it is in.\n",
    "            # Raw HTML of the desired table cell:\n",
    "            # <td class=\"Py(10px) Ta(start) Pend(10px)\"><span>Mar 11, 2019</span></td>\n",
    "            price_date = historical_price.select('td[class=\"Py(10px) Ta(start) Pend(10px)\"]')\n",
    "\n",
    "            # Proceed if a price date value is found.\n",
    "            # Notice how the price date related code is indented inside the \"if rows\" statement.\n",
    "            # This will skip over the rows with just a dividend value without all of the historical pricing data.\n",
    "            if price_date:\n",
    "                print(\"price_date HTML\", price_date)\n",
    "                print(\"price_date text:\",price_date[0].text,\"\\n\")\n",
    "                price_date = price_date[0].text\n",
    "\n",
    "                # Append the price date value to the price_date dictionary key.\n",
    "                historical_data['price_date'].append(price_date)\n",
    "\n",
    "    # This is why we created a Python dictionary to store the scraped results.\n",
    "    # Assign the Python dictionary to a Pandas DataFrame.\n",
    "    # By storing the data in a Pandas DataFrame we can manipulate the data then export the manipulated results.\n",
    "    # df is a variable name for the DataFrame.\n",
    "    df_dict[ticker] = pd.DataFrame(historical_data)\n",
    "\n",
    "    # The price_adj_close column is seen as an object and not a float.\n",
    "    # We want to convert price_adj_close to a float to allow for float operations within Excel.\n",
    "    df_dict[ticker]['price_adj_close'] = df_dict[ticker]['price_adj_close'].astype(float)\n",
    "\n",
    "    # price_date is listed as an object but will be treated as a string in Excel.\n",
    "    # Convert price_date to a datetime format for date-related operations.\n",
    "    df_dict[ticker]['price_date'] = pd.to_datetime(df_dict[ticker]['price_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure xlsxwriter module installed to create Excel xlsx files.\n",
    "# https://xlsxwriter.readthedocs.io/example_pandas_multiple.html\n",
    "\n",
    "excel_filename = 'historical_data.xlsx'\n",
    "\n",
    "writer = pd.ExcelWriter(excel_filename, engine='xlsxwriter')\n",
    "\n",
    "# Create a DataFrame of just the ticker symbols.\n",
    "tickers_df = pd.DataFrame(tickers, columns=['Ticker'])\n",
    "# Write the tickers DataFrame to its own sheet in the Excel file.\n",
    "tickers_df.to_excel(writer, sheet_name='Tickers', index=False)\n",
    "\n",
    "# Loop through the tickers.\n",
    "for ticker in tickers:\n",
    "    # Write the DataFrame for each ticker's historical prices to its own worksheet in the Excel file.\n",
    "    # Use the ticker as the sheet name.\n",
    "    df_dict[ticker].to_excel(writer, sheet_name=ticker, index=False)\n",
    "\n",
    "# Close the Pandas Excel writer and output the Excel file.\n",
    "writer.save()\n",
    "\n",
    "# Open historical_data.xlsx in Excel to verify the export.\n",
    "# historical_data.xlsx is written to the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
