{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Before importing the libraries below, make sure they are installed. You can use Anaconda-Navigator's GUI or it's command line program called conda. You can also use the pip command.\n",
    "Example install commands:\n",
    "\n",
    "conda install pandas\n",
    "pip install pandas\n",
    "\n",
    "conda install beautifulsoup4\n",
    "pip install beautifulsoup4\n",
    "'''\n",
    "\n",
    "# Import library to make HTTP requests, i.e fetch URL similar to a browser request\n",
    "import requests\n",
    "# Import web scraping library\n",
    "from bs4 import BeautifulSoup\n",
    "# Import data analysis and export library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Request Yahoo Finance URL for a ticker's history (date range defaults to the past year).\n",
    "# https://finance.yahoo.com/quote/SPY/history\n",
    "\n",
    "# Specify ticker to scrape.\n",
    "ticker = 'SPY'\n",
    "\n",
    "yahoo_finance_url = 'https://finance.yahoo.com/quote/' + ticker + '/history'\n",
    "page = requests.get(yahoo_finance_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return HTTP status code to check if URL request was successful.\n",
    "# https://httpstatuses.com/ for a description of HTTP status codes.\n",
    "page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display raw HTML content of the URL request.\n",
    "page.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign HTML content to a BeautifulSoup object to facilitate web scraping.\n",
    "# html.parser is one of four parser libraries.\n",
    "# Description of each parser library: https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-a-parser\n",
    "soup = BeautifulSoup(page.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert HTML content into a nicely formatted string for better readability.\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all of the HTML table rows containing the historical data by looking for an HTML tab and its defining attribute.\n",
    "# You can inspect the HTML elements by using the Chrome browser and right clicking over the desired element and clicking \"Inspect.\"\n",
    "# Raw HTML of the table row:\n",
    "# <tr class=\"BdT Bdc($c-fuji-grey-c) Ta(end) Fz(s) Whs(nw)\">\n",
    "historical_prices = soup.select('tr[class=\"BdT Bdc($c-fuji-grey-c) Ta(end) Fz(s) Whs(nw)\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm if the rows were found by printing the found HTML table rows.\n",
    "historical_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the first found row.\n",
    "# The index starts at 0. 0 equals the first element, 1 equalst the second element, etc.\n",
    "historical_prices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty Python dictionary data structure to keep track of the found price dates and the adjusted closing price for each row.\n",
    "# The value for each dictionary key is an empty list.\n",
    "# The number of items in the value list for the price_date and price_adj_close keys must be identical.\n",
    "# Dictionary initialization must be in the same cell to clear it out each time you're testing the scrape.\n",
    "# Data is appended and may lead to mismatched column counts.\n",
    "historical_data = {\n",
    "    'price_date' : [],\n",
    "    'price_adj_close' : []\n",
    "}\n",
    "\n",
    "# \"for\" loop through the found rows of historical data. Each row represents a single date.\n",
    "for historical_price in historical_prices:\n",
    "    \n",
    "    # Display a horizontal line to easily distinguish between each row.\n",
    "    print(\"\\n----------------\\n\")\n",
    "\n",
    "    # Price Adj Close\n",
    "    # Need to find price adj close first b/c not all rows have it due to a row with just the dividend.\n",
    "    # <td class=\"Py(10px) Pstart(10px)\"><span>278.25</span></td>\n",
    "    # Find the HTML table cell tag (td) with the class value of \"Py(10px) Pstart(10px)\"\n",
    "    rows = historical_price.select('td[class=\"Py(10px) Pstart(10px)\"]')\n",
    "\n",
    "    # Proceed if the HTML table cell tag is found with the class value defined above.\n",
    "    if rows:\n",
    "        # The following print statements are for debugging to show how the price adj close was found.\n",
    "        # Price Adj Close is the 5th HTML table cell.\n",
    "        # There are multiple HTML table cells with the class attribute value of \"Py(10px) Pstart(10px)\"\n",
    "        #print(rows)\n",
    "        print(\"price_adj_close HTML:\",rows[4])\n",
    "        # .text will exclude the HTML tags and only get the text.\n",
    "        # \"\\n\" is a newline to format the debugging output.\n",
    "        print(\"price_adj_close text:\",rows[4].text,\"\\n\")\n",
    "        price_adj_close = rows[4].text\n",
    "\n",
    "        # Append the found price adj close to the price_adj_close dictionary key which we'll reference later when exporting the results.\n",
    "        historical_data['price_adj_close'].append(price_adj_close)\n",
    "   \n",
    "\n",
    "        # Price Date\n",
    "        # The price date has its own unique class value for the HTML table cell that it is in.\n",
    "        # Raw HTML of the desired table cell:\n",
    "        # <td class=\"Py(10px) Ta(start) Pend(10px)\"><span>Mar 11, 2019</span></td>\n",
    "        price_date = historical_price.select('td[class=\"Py(10px) Ta(start) Pend(10px)\"]')\n",
    "\n",
    "        # Proceed if a price date value is found.\n",
    "        # Notice how the price date related code is indented inside the \"if rows\" statement.\n",
    "        # This will skip over the rows with just a dividdent value without all of the historical pricing data.\n",
    "        if price_date:\n",
    "            print(\"price_date HTML\", price_date)\n",
    "            print(\"price_date text:\",price_date[0].text,\"\\n\")\n",
    "            price_date = price_date[0].text\n",
    "\n",
    "            # Append the price date value to the price_date dictionary key.\n",
    "            historical_data['price_date'].append(price_date)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the contents of the historical_data dictionary.\n",
    "# The list entries should line up. Check to see if the first list value for the price_adj_close key matches up to the first price_date value found on https://finance.yahoo.com/quote/SPY/history\n",
    "historical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is why we created a Python dictionary to store the scraped results.\n",
    "# Assign the Python dictionary to a Pandas DataFrame.\n",
    "# By storing the data in a Pandas DataFrame we can manipulate the data then export the manipulated results.\n",
    "# df is a variable name for the DataFrame.\n",
    "df = pd.DataFrame(historical_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the first 5 rows of the DataFrame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data types for each DataFrame column.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The price_adj_close column is seen as an object and not a float.\n",
    "# We want to convert price_adj_close to a float to allow for float operations within Excel.\n",
    "df['price_adj_close'] = df['price_adj_close'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# price_date is listed as an object but will be treated as a string in Excel.\n",
    "# Convert price_date to a datetime format for date-related operations.\n",
    "df['price_date'] = pd.to_datetime(df['price_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the data types were updated.\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting price_date to datetime will change the format from a string with the month name abbreviation to YYYY-MM-DD.\n",
    "# Output the first 5 rows to confirm the price_date change.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_filename = 'historical_data_' + ticker + '.csv'\n",
    "# Print the csv_filename for debugging.\n",
    "print(csv_filename)\n",
    "# Write the DataFrame's contents to a .csv file where the .csv filename has historical_data_ as a prefix, followed by the ticker value.\n",
    "# index=False omits the index column. Notice in df.head() the first column does not have a column name and starts with a 0 value. That is the index column.\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "# Verify the results by clicking on the generated .csv file from http://localhost:8885/tree or from File Explorer (Windows)/Finder (Mac)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Excel file named historical_data.xlsx with a single sheet where the sheet is renamed to the ticker.\n",
    "excel_filename = 'historical_data.xlsx'\n",
    "df.to_excel(excel_filename, sheet_name=ticker, index=False)\n",
    "\n",
    "# Open historical_data.xlsx in Excel to verify the export.\n",
    "# historical_data.xlsx is written to the same directory as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
